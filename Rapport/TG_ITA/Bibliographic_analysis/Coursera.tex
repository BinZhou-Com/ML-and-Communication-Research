\documentclass[12pt,a4paper]{report}
\newcommand{\dd}[1]{\mathrm{d}#1}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}
\section{Coursera}
\subsubsection{Week 1}
Machine Learning algorithms :
	Supervised learning
	Unsupervised learning
	Reinforcement Learning
	Recommender systems
	
	
Supervised Learning
	based on right answers
	Regression problem: predict continuous valued output (price)
	Classification problem: output value of 0 or 1
	%% COURSERA TEXT
	To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function h : X -> Y so that h(x) is a good predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. Seen pictorially, the process is therefore like this:
%%%%
	
Unsupervised Learning
%% COURSERA TEXT
	Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.

We can derive this structure by clustering the data based on relationships among the variables in the data.

With unsupervised learning there is no feedback based on the prediction results.
%%%%
	Not told what to do -> find some structure in data
	Clustering Algorithm
	not give the algorithm the right answers
	Cocktail party problem: take a data that seems dated together and separate them (two audio sources),  
	

Hypothesis Function
	
	
Cost Function
	Cost Function measures the accuracy of our hypothesis function.
		

Gradient descent Algorithm
	Optimize parameters in hypothesis function to minimize the cost function
	Convex functions has only a global optima, no local optima (good for working with)
	"Batch" gradient descent: each step of gradient descent uses all the training examples
	
	
Learning rate
	Controls how big the step is in the optimization process
	
	
\subsubsection{Week 2}
Fix a notation thorughout the work
	m -> the number of training examples i
	n -> the number of features j\\
	$ x^{(i)}_{j} $\\
	$ i = 1,...,m $\\
	$ j = 0,...,n $
	i are the lines and j the columns.
Gradient descent for multiple variables
	
Feature scale
	mean normalize data to converge faster (do not apply to inserted $ x_{0} $ that equals 1 for example). Adjust input values as shown in this formula.
	\begin{equation}
	x_{i} := \frac{x_{i}-\mu_{i}}{s_{i}}
	\end{equation}
	
	where $ \mu_{i} $ is the average of all values for feature (i) and $ s_{i} $ is the range of values ($ max(x_{i})-min(x_{i}) $) or the standard deviation of a given feature $ i $.
	get all features between -1 and 1 range or 0 and 1
	
Gradient descent $\mathcal{O}(n^{2})$
	\begin{equation}
	\theta_{j} := \theta_{j} - \alpha \frac{\partial}{\partial \theta_{j}}J(\theta)
	\end{equation}
	works well when n is large
	
Vectorized implementation of Gradient descent $\mathcal{O}(n^{2})$
	\begin{equation}
	\theta := \theta - \frac{\alpha}{m} X^{T}(g(X\theta)-Y)	
	\end{equation}
Learning rate
	how to choose: look graph min J vs No. of iterations. It should decrease at every iteration.

Polynomial regression
	Create new features to fit a polynomial regression to a linear regression.
	E.g.
	
	\begin{equation}
	x_{0} = (feature)
	\end{equation}
	
	\begin{equation}
	x_{1} = (feature)^{2}
	\end{equation}
	
	
Analytic solution (faster convergence)
	The value of $ \theta = (X^{T}X)^{-1}X^{T}y $ (normal equation) gives the optimal value of $\theta$ that minimizes $ J(\theta) $ and doesn't need feature scaling.
	Don't need to iterate nor choose $\alpha$.
	Compute the inverse costs a lot $\mathcal{O}(n^{3})$. So it is preferably to use if n is small over the iterative method.
	Noninvertibility: pinv -> pseudo inverse: calculates the value of the inverse even if it is non inversible. 
	
	\subsubsection{Week 3}
	
Classification problem: take a bunch of data and outputs discrete  values
	multi class: several discrete outcomes
	binary class: 2 outputs (0,1)
		
Logistic regression (classification algorithm): output is always between 0 and 1. sigmoid function or logistic function: $g(z) = \frac{1}{1+e^{-z}}$. Hypothesis: $h(x)=g(\theta^{T}x)$ maps any real number to the (0,l) interval. $h(x)$ will give the probability that our output is 1.


Decision boundary: line where the hypothesis equals to 0.5. Separates 2 regions, greater than and less than 0.5 to the hypothesis function. The decision boundaries can be linear or not.
	The decision boundary is a property of the hypothesis function. The greater the order of the polynomial, the more complex is the shape.
	
Cost function: find a function that is convex to arrive in a global minimum.

Optimization algorithms:
	\begin{itemize}
	\item Gradient descent
	\item Conjugate gradient
	\item BFGS
	\item L-BFGS
	\end{itemize}

No need to manually pick $\alpha$ in the 3 last algorithms. They are fasten than gradient descent. However, they are more complex


Multiclass classification
	One vs all (one vs rest)
 

	
Avoid overfitting: doesn't add too much features, otherwise the training data will not predict well values.	The cost function is almost zero to the training example.
	To fight this problem: reduce the number of features (select which features to keep), regularization (keep all features but reduce the magnitude of parameters theta), Regularization works well when we have a lot of slightly useful features.
	Add a regularization term in the end of the cost function. A regularization parameter is set to make a trade off between how well the data is fitted and weakening the parameters theta.
	
In the end we have a regularized linear regression that works much better than the regular one. It even avoid that the normal equation is non-reversible. The calculus is the same, but we add an extra term to the cost function.	To calculate the gradient descent, one must actualize the value of theta 0 and of others thetas, since the added sum takes from indexes 1 to n. The value of theta 0 is known as bias.

Regularized cost function:
\begin{equation}
J(\theta) = \frac{1}{2m} \sum_{n=1}^{m} (h(x^{(i)})-y^{(i)})^{2} + \lambda\sum_{n=1}^{n} \theta_{j}^{2}
\end{equation}

Cost Function in logistic regression

...	
	
\subsubsection{Week 4 - Neural Networks}
	
	Neural network: more efficient way to learn complex hypothesis.
	
	\textbf{Model 1 representation: }
	\begin{itemize}
	\item Dendrite: input wires
	\item Axon: output wire
	\item Cell body: do computations
	\item axon send info to another neuron
	\end{itemize}
	
	Hypothesis function = activation function
	
	$\theta$ = parameters = weights
	
	Layers: first layer: input layer, last layer: output layer, hidden layer: values you don't observe between the input and output.
	
	Notation: $\Theta^{j}$ - matrix of weights controlling function mapping from layer $j$ to layer $j+1$. The dimension is equal to $s_{j+1} \times (s_{j}+1)$. The index +1 takes into account the bias added to the inputs and to the computed layer.; $a_{i}^{(j)}$ - activation of unit $i$ in layer $j$; 
	
	\textbf{Model Representation II}
	Vectorized: forward propagation:
	
	\begin{align}\label{eq:my_eq}
	z^{(j)} = & \Theta^{(j-1)}a^{j-1} \\
	a^{(j)} = & g(z^{(j)})
	\end{align}
	
Last layer: 	
\begin{align}\label{eq:my_eq}
	z^{(j+1)} = & \Theta^{(j)}a^{j} \\
	a^{(j+1)} = & g(z^{(j+1)}) = h_{\Theta}(x)
	\end{align}
	
	The away a NN is connected is called an architecture.	
	The first layers computes task of a certain complexity that increases when we go deeper into the network. The last layer usually computes the most demanding task.
	
	Multiclass Classification
	To classify data into multiple classes, we let our hypothesis function return a vector of values. 
	
	Task 3: Multi-class Classification and Neural Networks (matlab)
	
	\subsubsection{Week 5}
\end{document}















