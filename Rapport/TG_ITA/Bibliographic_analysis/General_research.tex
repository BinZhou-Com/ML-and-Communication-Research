\documentclass[12pt,a4paper]{report}
\newcommand{\dd}[1]{\mathrm{d}#1}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{tikz}
\begin{document}
\section{General Research}
\subsubsection{Communication Chain}


Communication is the act of conveying intended meanings from one entity or group to another through the use of mutually understood signs and semiotic rules

\subsection{Introduction to digital communication}

Claude Channon - creation of Informational Technology

Step by step of a communication system: 
	1. Communication sources  : speech waveforms,
image waveforms, text files, as being representable by binary sequences
	2. convert the source output into a binary sequence
	3. convert that binary sequence into a form suitable for transmission over particular physical media
such as cable, twisted wire pair, optical fiber, or electromagnetic radiation through space.

	\textbf{Digital communication systems}, by definition, are communication systems that use such a digital1
sequence as an interface between the source and the channel input (and similarly between the
channel output and final destination) 

Placing a binary interface between source and channel. The source encoder converts the source output to a binary sequence and the channel encoder (often
called a modulator) processes the binary sequence for transmission over the channel.
The channel decoder (demodulator) recreates the incoming binary sequence (hopefully
reliably), and the source decoder recreates the source output

Benefits of a digital interface between source and channel:
\begin{itemize}
\item Digital hardware has become so cheap, reliable, and miniaturized, that digital interfaces are
eminently practical.
\item A standardized binary interface between source and channel simplifies implementation and
understanding, since source coding/decoding can be done independently of the channel,
and, similarly, channel coding/decoding can be done independently of the source
\item A standardized binary interface between source and channel simplifies networking, which
now reduces to sending binary sequences through the network
\item One of the most important of Shannon’s information theoretic results is that if a source
can be transmitted over a channel in any way at all, it can be transmitted using a binary
interface between source and channel. This is known as the source/channel separation
theorem
\end{itemize}

Definition of a digital sequence: A digital sequence is a sequence made up of elements from a finite alphabet (e.g., the binary digits {0, 1},
the decimal digits {0, 1, . . . , 9} )


Fundamental architectural principles:
	\textit{Standarized interfaces} and \textit{layering}
	A standardized interface allows the user or equipment on one side of the interface to ignore all
details about the other side of the interface except for certain specified interface characteristics
	The idea of layering in communication systems is to break up communication functions into a
string of separate layers as illustrated in Figure 1.2.
Each layer consists of an input module at the input end of a communcation system and a peer
output module at the other end. The input module at layer i processes the information received
from layer i+1 and sends the processed information on to layer i-1. The peer output module at
layer i works in the opposite direction, processing the received information from layer i-1 and
sending it on to layer i.

Encoding and decoding - basics: layer modulator as converting a
binary sequence to a waveform, with the peer demodulator converting the waveform back to the binary sequence

\subsubsection{Source coding}
	Discrete source:
	function of converting the input from its original
form into a sequence of bits

	The simplest source coding techniques apply to discrete sources and simply involve representing
each succesive source symbol by a sequence of binary digits
	upper-case letters, lower-case
letters, and a great many special symbols may be converted into 8-bit blocks (“bytes”) using
the standard ASCII code

\subsubsection{Communication channels}

	Channel encoding and decoding when the channel is the physical medium (either with or without amplifiers, antennas, lasers, etc.) is usually called (digital) modulation and demodulation
respectively. 


	binary sequence is first converted to a baseband
waveform and the resulting baseband waveform is converted to bandpass by the same type of
procedure used for analog modulation. As will be seen, the challenging part of this problem is the conversion of binary data to baseband waveforms.


	As in the study of any type of system, a channel is usually viewed in terms of its possible inputs,
its possible outputs, and a description of how the input affects the output. This description is
usually probabilistic. If a channel were simply a linear time-invariant system (e.g., a filter), then
it could be completely characterized by its impulse response or frequency response. However,
the channels here (and channels in practice) always have an extra ingredient— noise


	it was Shannon, in 1948, who realized that noise provides
the fundamental limitation to performance in communication systems


	Channel model: $ y(t) = u(t) + w(t) $
	where $u(t)$ is a waveform input and $w(t)$ an added noise waveform. Both waveform are viewed as random processes.
	Types of channels: Additive channel model, Linear Gaussian channel (the waveform u is filtered), random variably channels, etc.
	The channel with encoder and decoder is called \textit{physical layer}.
	
	\subsubsection*{Modulations}
	
	2-PAM modulation: binary pulse amplitude modulation. Bits -1/1 instead of 0/1.
	
	\subsubsection{Error correction}
	
	channel encoder separated in two layers: error-correcting code and a simple modulator.
	
	Shannon showed was the very unintuitive fact that more sophisticated coding schemes can
achieve arbitrarily low error probability at any data rate above a value known as the \textit{channel capacity.}

	The channel capacity is a function of the probabilistic description of the output conditional on each possible input. Conversely, it is not possible to achieve low error probability at rates above the channel capacity.
	
	
	\subsubsection{Definitions}
	\begin{itemize}
	\item $E_{b}$, energy per bit.
	\item $E_{s}=nE_{b}$, energy per symbol with $n$ bits.
	\item $T_{b}$, bit duration.
	\item $\frac{1}{2}N_{0}$, noise power spectral density (W/Hz)
	\item $P_{b}$, probability of bit-error.
	\item $P_{s}$, probability of symbol-error.
	\end{itemize}
	
	
\end{document}