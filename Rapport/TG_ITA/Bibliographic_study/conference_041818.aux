\relax 
\citation{b1}
\citation{b2}
\citation{b3}
\citation{osheaautoencoder}
\citation{2018}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Motivation}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Related work}{1}\protected@file@percent }
\citation{b4}
\citation{b7}
\citation{b6}
\citation{b6}
\citation{b5}
\citation{b6}
\citation{b9}
\citation{b8}
\citation{b9}
\citation{b2}
\citation{b8}
\citation{b10}
\citation{b2}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Problem statement}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Theoretical Background}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Maximum a posteriori decoder}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Neural network basics}{2}\protected@file@percent }
\newlabel{eq:eqFP}{{1}{2}}
\newlabel{eq:c-e}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces MLNN representative diagram. Where \textbf  {x} is the input vector of the NN, $\textbf  {r}_{l}$ is a hidden layer vector and \textbf  {y} is the output vector.}}{2}\protected@file@percent }
\newlabel{fig:NN}{{1}{2}}
\citation{b8}
\citation{b9}
\citation{b11}
\citation{b12}
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\bibcite{b7}{7}
\bibcite{b8}{8}
\bibcite{b9}{9}
\bibcite{b10}{10}
\bibcite{b11}{11}
\bibcite{b12}{12}
\bibcite{osheaautoencoder}{13}
\bibcite{2018}{14}
\newlabel{eq:o-c-e}{{3}{3}}
\@writefile{toc}{\contentsline {section}{References}{3}\protected@file@percent }
