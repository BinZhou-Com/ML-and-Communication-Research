\begin{thebibliography}{10}

\bibitem{Shannon:2001:MTC:584091.584093}
C.~E. Shannon, ``A mathematical theory of communication,'' {\em SIGMOBILE Mob.
  Comput. Commun. Rev.}, vol.~5, pp.~3--55, Jan. 2001.

\bibitem{DBLP:journals/corr/CalabreseWGPS16}
F.~D. Calabrese, L.~Wang, E.~Ghadimi, G.~Peters, and P.~Soldati, ``Learning
  radio resource management in 5g networks: Framework, opportunities and
  challenges,'' {\em CoRR}, vol.~abs/1611.10253, 2016.

\bibitem{DBLP:journals/corr/OSheaH17}
T.~J. O'Shea and J.~Hoydis, ``An introduction to machine learning
  communications systems,'' {\em CoRR}, vol.~abs/1702.00832, 2017.

\bibitem{2016arXiv160806409O}
T.~J. {O'Shea}, K.~{Karra}, and T.~C. {Clancy}, ``{Learning to Communicate:
  Channel Auto-encoders, Domain Specific Regularizers, and Attention},'' {\em
  arXiv e-prints}, Aug. 2016.

\bibitem{2017arXiv171008379G}
D.~{Goldin} and D.~{Burshtein}, ``{Performance Bounds of Concatenated Polar
  Coding Schemes},'' {\em arXiv e-prints}, Oct. 2017.

\bibitem{Worm00turbo-decodingwithout}
E.~Worm, S.~Member, P.~Hoeher, S.~Member, and N.~Wehn, ``Turbo-decoding without
  snr estimation,'' {\em IEEE Communications Letters}, pp.~193--195, 2000.

\bibitem{Viterbi}
A.~J. Viterbi, ``Error bounds for convolutional codes and an asymptotically
  optimum decoding algorithm,'' {\em IEEE Transactions on Information Theory},
  vol.~IT-13, pp.~260--269, April 1967.

\bibitem{journals/ett/RobertsonHV97}
P.~Robertson, P.~A. Hoeher, and E.~Villebrun, ``Optimal and sub-optimal maximum
  a posteriori algorithms suitable for turbo decoding.,'' {\em European
  Transactions on Telecommunications}, vol.~8, no.~2, pp.~119--125, 1997.

\bibitem{HagenauerJ}
H.~J., R.~P., and P.~L., ``iterative turbo decoding of systematic convolutional
  codes with the map and sova algorithms,'' pp.~21 -- 29, 10 1994.

\bibitem{JordanMA}
M.~Jordan and R.~Nichols, ``The effects of channel characteristics on turbo
  code performance,'' pp.~17 -- 21 vol.1, 11 1996.

\bibitem{Ibnkahla}
M.~Ibnkahla, ``Applications of neural networks to digital
  communications-survey,'' {\em Signal Processing}, vol.~80, pp.~1185--1215, 07
  2000.

\bibitem{nielsenneural}
M.~A. Nielsen, ``Neural networks and deep learning,'' 2018.

\bibitem{murphy2013machine}
K.~P. Murphy, {\em Machine learning : a probabilistic perspective}.
\newblock Cambridge, Mass. [u.a.]: MIT Press, 2013.

\bibitem{DBLP:journals/corr/AbadiABBCCCDDDG16}
M.~Abadi, A.~Agarwal, P.~Barham, E.~Brevdo, Z.~Chen, C.~Citro, G.~S. Corrado,
  A.~Davis, J.~Dean, M.~Devin, S.~Ghemawat, I.~J. Goodfellow, A.~Harp,
  G.~Irving, M.~Isard, Y.~Jia, R.~J{\'{o}}zefowicz, L.~Kaiser, M.~Kudlur,
  J.~Levenberg, D.~Man{\'{e}}, R.~Monga, S.~Moore, D.~G. Murray, C.~Olah,
  M.~Schuster, J.~Shlens, B.~Steiner, I.~Sutskever, K.~Talwar, P.~A. Tucker,
  V.~Vanhoucke, V.~Vasudevan, F.~B. Vi{\'{e}}gas, O.~Vinyals, P.~Warden,
  M.~Wattenberg, M.~Wicke, Y.~Yu, and X.~Zheng, ``Tensorflow: Large-scale
  machine learning on heterogeneous distributed systems,'' {\em CoRR},
  vol.~abs/1603.04467, 2016.

\bibitem{chollet2015keras}
F.~Chollet {\em et~al.}, ``Keras.'' \url{https://keras.io}, 2015.

\bibitem{doi:10.1162/neco.2006.18.7.1527}
G.~E. Hinton, S.~Osindero, and Y.-W. Teh, ``A fast learning algorithm for deep
  belief nets,'' {\em Neural Computation}, vol.~18, no.~7, pp.~1527--1554,
  2006.
\newblock PMID: 16764513.

\bibitem{DBLP:conf/acssc/BenammarP18}
M.~Benammar and P.~Piantanida, ``Optimal training channel statistics for
  neural-based decoders,'' in {\em 52nd Asilomar Conference on Signals,
  Systems, and Computers, {ACSSC} 2018, Pacific Grove, CA, USA, October 28-31,
  2018} (M.~B. Matthews, ed.), pp.~2157--2161, {IEEE}, 2018.

\bibitem{DBLP:journals/corr/KeskarMNST16}
N.~S. Keskar, D.~Mudigere, J.~Nocedal, M.~Smelyanskiy, and P.~T.~P. Tang, ``On
  large-batch training for deep learning: Generalization gap and sharp
  minima,'' {\em CoRR}, vol.~abs/1609.04836, 2016.

\end{thebibliography}
